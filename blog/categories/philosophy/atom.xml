<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: philosophy | Ashton Kemerling]]></title>
  <link href="http://AshtonKem.github.io/blog/categories/philosophy/atom.xml" rel="self"/>
  <link href="http://AshtonKem.github.io/"/>
  <updated>2013-05-03T20:13:20-05:00</updated>
  <id>http://AshtonKem.github.io/</id>
  <author>
    <name><![CDATA[Ashton Kemerling]]></name>
    <email><![CDATA[ashtonkemerling@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Right vs. Useful]]></title>
    <link href="http://AshtonKem.github.io/blog/2013/01/03/right-vs-useful/"/>
    <updated>2013-01-03T21:21:00-06:00</updated>
    <id>http://AshtonKem.github.io/blog/2013/01/03/right-vs-useful</id>
    <content type="html"><![CDATA[<p>I spend a fairly decent amount of my time thinking about how my mindset and world view affects my decisions and actions. In the past few months I’ve found that how I evaluate these mindsets has begun to change; I used to be mostly concerned with whether or not a mindset was correct, but now I’ve started to think about whether or not it’s useful.</p>

<p>Determining whether or not a mindset is correct is rather tricky philosophical ground, as it requires some sort of platonic “reality” to compare it against. But for the sake of argument, let us say that a “correct” mindset matches the most unbiased observations of the world we can make, or logically follows from a set of axioms that are relatively well accepted. Good examples of correct mindsets are “Not lying on my taxes reduces the chance of getting in trouble”, and “driving according to traffic laws means I won’t get a ticket”.</p>

<p>Useful mindsets are even easier. A useful mindset is one that produces more beneficial outcomes for the user, where beneficial is also defined by the user. The best examples of useful mindsets are also correct, those who don’t speed don’t get speeding tickets, etc.</p>

<p>Where things get interesting is where useful and right don’t necessarily agree, or when it’s not currently possible to know what is correct. My particular favorite is the question of free will: It’s not currently known whether or not humans make actual decisions, or if we are merely a product of a deterministic universe.</p>

<p>Whether or not we have free will is probably beyond our current philosophical and scientific knowledge, and it’s certainly beyond mine. But we can analyze what our belief in free will does to our ability. The inputs to this scenario can be put on a 2×2 grid, 2 options for our belief (free will or not), 2 for reality (free will or deterministic), producing 4 options. If we choose to believe and free will, and free will exists we gain our own future. If we choose to believe in free will, and it doesn’t exist, we were predestined to believe as such, ditto if we don’t believe and free will doesn’t exist. But the really painful point is when we choose to not believe in free will and it exists, we end up surrendering our initiative and free well, blaming everything on fate. The obvious choice is to believe in free will, and hope for the best.</p>

<p>The more astute among you will recognize this as Pascal’s wager (which is also a form of the more general Prisoners Dilemna). Personally Pascal’s wager has never swayed my belief, as I’ve found reasons to disagree with its setup (the wager only works if you assume free will, and a vengeful Abrahamic God. If you disagree with this portrayal of a higher being, Pascal’s wager doesn’t work out the same).</p>

<p>So next time you find yourself thinking about your worldview, try using usefulness as another yardstick to compare your beliefs against.</p>
]]></content>
  </entry>
  
</feed>
